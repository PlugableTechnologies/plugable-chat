[package]
name = "plugable-chat"
version = "0.0.0"
description = "A Plugable Chat Application"
authors = ["you"]
edition = "2021"

[lib]
name = "plugable_chat_lib"
crate-type = ["staticlib", "cdylib", "rlib"]

[build-dependencies]
tauri-build = { version = "^2", features = [] }

[dependencies]
tauri = { version = "^2", features = [] }

serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
json5 = "0.4"
tokio = { version = "1", features = ["full"] }
futures = "0.3"
uuid = { version = "1.0", features = ["v4", "serde"] }
chrono = "=0.4.38"

# LanceDB & Arrow Stack (Pinning versions as per plan)
lancedb = "0.4"
arrow = "51.0" 
arrow-array = "51.0"
arrow-schema = "51.0"
reqwest = { version = "0.12.24", features = ["json"] }

# Local embeddings via ONNX Runtime
fastembed = "4"

# File hashing for cache invalidation
sha2 = "0.10"

# Fast CRC32 for file-level cache
crc32fast = "1.4"

# LRU cache for embedding caching
lru = "0.12"

# Home directory detection for config files
dirs = "5"

# CLI argument parsing
clap = { version = "4", features = ["derive", "env"] }

# Text diffing for optimized logging
similar = "2.4"

# Regex for parsing tool calls
regex = "1"

# URL encoding for API calls
urlencoding = "2"

# Python syntax parsing (for pre-exec validation)
rustpython-parser = { version = "0.4", default-features = false }

# Lazy static for profile registry
lazy_static = "1.4"

# WASM runtime for Python sandbox
wasmtime = "22"
wasmtime-wasi = "22"

# Async channel for WASM callbacks  
async-channel = "2"

# Python sandbox for code execution
python-sandbox = { path = "crates/python-sandbox" }
mcp-test-server = { path = "../mcp-test-server" }

# PDF text extraction (pdf-extract has better font encoding handling than raw lopdf)
pdf-extract = "0.9"

# DOCX parsing (DOCX = ZIP with XML)
zip = "0.6"

[dependencies.tauri-plugin-opener]
version = "2"

[dependencies.tauri-plugin-dialog]
version = "2"

[dev-dependencies]
tempfile = "3"

# ONNX Runtime with platform-specific GPU support:
# - Windows: CUDA + TensorRT (NVIDIA GPUs)
# - macOS: CoreML only (Apple Silicon/Intel GPUs)
# - Linux: CUDA + TensorRT (NVIDIA GPUs)
[target.'cfg(target_os = "windows")'.dependencies]
ort = { version = "2.0.0-rc.9", features = ["cuda", "tensorrt"] }

[target.'cfg(target_os = "macos")'.dependencies]
ort = { version = "2.0.0-rc.9", features = ["coreml"] }

[target.'cfg(target_os = "linux")'.dependencies]
ort = { version = "2.0.0-rc.9", features = ["cuda", "tensorrt"] }
